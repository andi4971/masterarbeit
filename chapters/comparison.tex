\chapter{Comparison of AST-Generation methods}

This chapter compares the three implementations for the AST-Generation using ANTLR. The visitor-pattern, listener-pattern and attributed grammar implementation are discussed. They are compared in the following aspects:

\begin{itemize}
    \item Ease of use
    \item Maintainability
    \item Performance
    \item Complexity
\end{itemize}

Lastly, an overall recommendation is given, based on the considered aspects. 

\section{Ease of use}

Ease of use describes how simple it is to implement the generation of an AST using a given approach. This section highlights the advantages and disadvantages of each approach.  

\subsection{Listener-Pattern}

The main benefit of the listener-pattern is that it does not require manual traversal of the syntax tree. This aspect is taken care of by the generated parser. Only the listener needs to be defined and registered to the parser. Every time a node is entered and exited, the respective listener method is called. For the generation of an AST, this leads naturally to the usage of stacks to manage already parsed nodes. ANTLR performs top-down parsing meaning that it will first enter a higher-level node, then enter and exit all the lower-level nodes, before exiting the higher-level node. To keep track of all the parsed nodes, stacks can be used. If the node requires one or more elements of a lower-level node it can pop the necessary amount from the stack. It is also possible to rely on the provided \verb|ParseContext| and generate the necessary AST nodes from it. This approach however defeats the purpose of using the listener-pattern. As soon as non-terminal child nodes are processed from the \verb|ParseContext|, a manual traversal of the syntax tree is performed. This means that nodes end up being processed twice unnecessarily. 

The solution to this is to strictly only process terminal nodes in a listener method and retrieve all non-terminal child nodes via stacks. For more complex applications this may lead to many stack instances being created and thus increasing the length of the listener implementation. Including the \verb|enter| and \verb|exit| methods for each node, it is possible for the source file to grow to multiple hundred lines of code just from method stubs and stack definitions. 

ANTLR offers ways to deal with unnecessary large listener implementations, by providing a \verb|BaseListener| implementation. This \verb|BaseListener| contains empty implementations for all \verb|enter| and \verb|exit| methods. 
Extending the \verb|BaseListener| allows for the implementation to only considers the methods of nodes that are relevant to the generation of the AST. For more complex applications, the source code may still reach multiple hundred lines of code, even when relying on the \verb|BaseListener|. 

It is possible to split the listener implementation into multiple files since ANTLR allows the registration of more than one listener at the same time. Each file must then only handle a subset of all nodes, decreasing file length. The flip side of this approach is that then communication between the listeners becomes a necessity. A listener that requires a node that another listener processed, must be able to retrieve the node from that listener's stack. This can significantly increase the complexity. In the listener-implementation of this thesis' compiler, there are 43 listeners implemented that all need to communicate with each other. 


\subsection{Visitor-Pattern}

When using the visitor-pattern, the syntax tree is already parsed and can be manually traversed to generate the AST. A visitor processes a node and proceeds to call other visitors that provide the AST nodes. Depending on the grammar and use case it can be preferred to have manual control over the traversal to e.g. only process a node under specific circumstances.  

Similar to the \verb|BaseListener|, ANTLR also generates a \verb|BaseVisitor| that contains empty implementations for the \verb|visit| methods of all nodes of the syntax tree. A concrete visitor then only needs to override the methods that are relevant for the AST node it generates. Each visitor has a generic type parameter that determines the visitor method's return type. This enables a setup in which each visitor is responsible for exactly one AST node type, leading to a separation of concerns. Again similar to the listener-pattern, the compiler in this master thesis contains 37 visitors. It would also be possible to implement everything in one visitor, however this would lead to the same problems discussed for the listener implementation.  

Compared to the listener-implementation the visitor-implementation may seem a bit more complicated due to the inversion of control. When using visitors, the nodes of the syntax tree are not traversed directly by accessing the values, but by calling the respective visitor method of each node. 

\subsection{Attributed Grammar}

From an ease of use perspective, using an attributed grammar or short ATG, proves to be the simplest option. All necessary code can be directly embedded into the grammar file, showing clearly which rule causes what code to be executed. ANTLR allows to also embed code in the grammar file that is unrelated to a specific rule in order to e.g. define variables or methods. The system is also flexible enough to allow for referencing of methods or variables defined outside the grammar file. For example, with this longer method implementations can be extracted into a separate file. 

Semantic actions can be added before, between and after every symbol, allowing for fine-grained control over when a specific piece of code should be executed. Further, semantic predicates enable to dynamically alter the generated language, allowing for more complex use cases to be implemented directly in the grammar. 

The tooling support for implementing attributed grammars is somewhat limited. For this master thesis IntelliJ IDEA with the ANTLR plugin was used. While it offers syntax highlighting for all lexical and semantic rules, no highlighting or linting is performed on the code of the semantic actions. This means that to notice an error in the code, the parser must be generated, and its code inspected. This can lead to unexpected errors and makes the development in general more time-consuming.

\section{Maintainability}

Maintainability is relevant for adapting and extending an already existing compiler codebase. When the grammar is modified, the AST generation must be adapted as well in most cases. Depending on the implementation, the adaption might be more or less complicated. 

\subsection{Listener-Pattern}

Extending the AST generation when using the listener-pattern requires the implementation of the \verb|enter| and \verb|exit| methods of the newly added syntax nodes. All existing methods where these nodes are required need to be adapted. Depending on what semantic information the new syntax nodes contain, methods that do not directly depend on those nodes may also need to be adapted. This can be complicated if the logic is spread out over multiple files. When multiple listeners are used, every listener would need to be adapted where these syntax nodes are relevant. 

Due to the implicit traversal of the syntax tree, it is not inherently obvious when the order of traversal has changed. This can lead to errors in the generation of the AST that may be difficult to detect and fix. As the application continues to grow and more listeners and stacks are added, it becomes more complex and difficult to understand.- This is especially the case if the code is spread out over multiple files.  

\subsection{Visitor-Pattern}

In case the grammar gets extended, and new rules are added, a visitor needs to be created for every type that is relevant to the AST. The visitor then implements all the \verb|visit| methods that are relevant for the AST node it produces. In case an existing rule is modified, and new symbols are added to it, only the \verb|visit| method for that specific rule needs to be adapted. 

The visitor-pattern is less error-prone, because all \verb|visit| methods return a value, eliminating the need for manual state tracking with e.g. stacks. The explicit traversal of the syntax tree makes it easier to follow the execution flow during debugging, since the developer is directly in control of the traversal order. If the traversal order must be updated, only the \verb|visit| methods for the specific sections must be updated, without having to modify the grammar. Just by looking at the code for the visitors it is possible to follow the execution flow.

\subsection{Attributed Grammar}

Performing changes on an attributed grammar is straightforward, as the rules and semantic actions are both contained in the same file. It is clearly visible when performing a change on a rule, how the associated semantic action is affected. Although, for more complex rules and grammars the intertwining of symbols and semantic actions can make the attributed grammar difficult to read. ANTLR offers the possibility to split up grammars into multiple files, which can help with excessively long files. 

Similar to the listener-pattern some form of manual state management in the form of stacks is often necessary, resulting in additional effort when adding or modifying rules. In contrast to the listener-pattern however, the execution flow is clearly understandable from the grammar. 

A potentially significant problem when using an attributed grammar is caused by intertwining code into the grammar. A feature of ANTLR is that it can generate a parser for multiple host languages from the same grammar file. However, by including code in the grammar file itself, this ability is lost. The parser can then only be generated for the programming language that is used to write the semantic actions. It is possible to maintain another version of the grammar without any programming language dependent code, however this requires additional work and could prove to be another source of errors if discrepancies between the two versions of the grammar arise. Since semantic actions are embedded into the parser, debugging must also be performed directly in the parser code. This can be challenging as the generated parser code is difficult to understand due to its nature as a state machine.

\section{Performance}

The performance of each implementation is evaluated by parsing a source file and measuring the time it takes until the AST is generated. Time measurement is performed by the built-in Kotlin function \verb|measureTime|. Further, the memory consumption is also measured. For this, the difference between the total available memory and free memory is calculated. Via \verb|Runtime.getRuntime()|, the current runtime information can be retrieved, and the \verb|freeMemory()| and \verb|totalMemory()| methods provide the total and free memory. Source code files of different lengths are used to show how each implementation deals with smaller and larger files. For each source file and implementation the evaluation is performed three times and an average is taken. The following file sizes are used:

\begin{itemize}
    \item 98kb,
    \item 952kb,
    \item 9504kb and
    \item 28527kb.
\end{itemize}


\subsection{Runtime}

Table \ref{tab:ParseRuntime} shows the measured runtime for each implementation. The last row shows the runtime required just for generating the syntax tree. Through this, the overhead required for constructing the AST can be determined. Across all implementations, their runtime grows at a higher rate than just for parsing. The ATG implementation consistently performs the best among all three implementations, showing the smallest overhead. This is due to the fact that the ATG generates the AST during the parse and does not require a traversal of the generated syntax tree. When looking at the visitor implementation, it can be seen that the overhead due to the traversal of the syntax tree is relatively limited. The overhead percentually gets smaller for larger files. The runtime of the visitor and ATG implementations also increase at roughly the same rate. 

The outlier in this statistic is the listener implementation. It has by far the longest runtime compared to all other implementations. This is largely due to the fact that multiple listeners are used for the implementation. Using multiple listeners makes the code more structured and easy to understand, however it significantly increases the required runtime. Each listener extends the \verb|minicppBaseListener|, which provides empty implementations for all listener methods. Each listener is only interested in a few of those methods, meaning that the invocations of all other methods serves no purpose. With over 40 different listeners this leads to many unnecessary invocations and thus increasing the runtime. The alternative is to implement everything inside one listener, at the cost of significantly worse code readability.


\begin{table}[!ht]
    \centering
    \caption{Time required to parse MiniC\texttt{++} source code with each implementation of the frontend.}
    \label{tab:ParseRuntime}
    \begin{tabular}{|r|r|r|r|r|}
    \hline
         & 98kb File & 952kb File & 9504kb File & 28527kb File \\ \hline
        \textbf{Visitor} & 134ms & 302ms & 2985ms & 12733ms \\ \hline
        \textbf{Listener} & 424ms & 2439ms & 24505ms & 76688ms \\ \hline
        \textbf{ATG} & 97ms & 201ms & 2484ms & 10845ms \\ \hline
        \textbf{Parse only} & 62ms & 131ms & 1317ms & 4274ms \\ \hline
    \end{tabular}
\end{table}


\subsection{Memory consumption}

Table \ref{tab:ParseMemory} shows the measured memory consumption for each implementation. The last row again shows the memory consumption for just the generation of the syntax tree. The visitor implementation consistently consumes the most memory, with quite an overhead when compared to just parsing. This is in parts due to the fact, that it must maintain the full syntax tree while generating the AST. Each visitor also instantiates other visitors, further increasing memory consumption. In contrast, the listener implementation consistently consumes the least amount of memory, although the difference to the ATG implementation is rather small. 


\begin{table}[!ht]
    \centering
    \caption{Memory consumption during the parse of MiniC\texttt{++} source code with each implementation of the frontend.}
    \label{tab:ParseMemory}
    \begin{tabular}{|r|r|r|r|r|}
    \hline
         & 98kb File & 952kb File & 9504kb File & 28527kb File \\ \hline
        \textbf{Visitor} & 20.7MB & 130.0MB & 1424.1MB & 3742.4MB \\ \hline
        \textbf{Listener} & 12.5MB & 121.6MB & 1251.8MB & 3456.2MB \\ \hline
        \textbf{ATG} & 14.2MB & 123.4MB & 1311.8MB & 3687.9MB \\ \hline
        \textbf{Parse only} & 11.0MB & 101.0MB & 1009.4MB & 2901.1MB \\ \hline
    \end{tabular}
\end{table}


\section{Recommendation}

For this recommendation, all aspects shown in this chapter are considered. Each implementation has aspects where it performs better than the other implementations. Taking all aspects into consideration, overall the visitor implementation is the best for most use cases. Although it is slower and consumes more memory during parse, than the ATG implementation, it makes up for that in maintainability and ease of use. Grammars steadily evolve and therefore, the amount of work needed to adapt the AST generation is a significant factor in choosing which strategy to use for the implementation. Separating the code for each AST node into a separate file, makes possible changes in the future, easier to implement. Further, being able to manually determine the order of traversal, allows for greater flexibility.

In case performance is of upmost importance, implementing the AST generation via an ATG is the best option. It consistently shows the least amount of overhead, and since everything is contained in one file, the complexity is limited. For less complex grammars, using an ATG for the AST generation does not pose any problems in terms of maintainability, except locking in to one host language. Another option is to implement the AST generation with the listener pattern. This allows for a clean separation between the grammar and the AST generation related code. However, the traversal is more difficult to follow when using listeners. With an ATG it is clearly visible when which piece of code will be executed. The vastly reduced performance when using multiple listeners, nullifies any benefits gained from better code structure.

\section{Summary}

This chapter discussed the advantages and disadvantages of each frontend implementation. The implementations were compared in regard to ease of use, maintainability and performance. Based on this, a recommendation was given. The next chapter summarizes the master thesis.