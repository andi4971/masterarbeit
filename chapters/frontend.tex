\chapter{Methods and Tools for Compiler Frontends}

In this chapter, methods and tools for the construction of compiler frontends are explained. This explanation focuses on the parser generator ANTLR. The basis for this chapter is the book "The Definitive ANTLR 4 Reference" by \textcite{Antlr4Reference}.

\section{Attributed Grammars}

Parser generators like ANTLR or Coco-2 require the definition of the grammar of the source language in a specific format. These formats also allow for the declaration of attributes and semantic actions in the grammar. Semantic actions have access to the attributes of symbols (terminal and non-terminal) of a rule. Some symbols have attributes associated with them. The combination of a grammar, attributes and semantic actions is called an attributed grammar (ATG).  


There are two types of attributes: inherited and synthesized attributes. The former ones are computed based on the attributes of the parent node. Synthesized attributes are based on the attributes of the children nodes.  
The type of attributes available depends on the parsing strategy. For a top-down strategy the attributes of child-nodes are not available, as they have not been parsed yet. Conversely, when using the bottom-up strategy, the attributes of parent nodes are not available. 

Especially relevant are the attributes of terminal classes. Through the attribute of a terminal class like \texttt{number}, the actual number that this class node holds can be accessed. These kinds of attributes are provided by the lexical analyzer. 

In listing \ref{lst:Coco2ATG} a simple attributed grammar for Coco-2 for arithmetic expressions is shown. This grammar uses semantic actions to calculate the result of an arithmetic expression. Semantic actions are encoded inside \lstinline{SEM<< >>} blocks; in this case with C\verb|#| code. Synthesized attributes provide the results of the calculations from the child nodes. These attributes are available inside the semantic actions where the actual calculation is performed. 

While it is convenient to embed semantic actions directly into the grammar, it is not without disadvantages. By embedding code of a specific language, it is no longer possible to use the same grammar to generate a parser in another implementation language. Parser generators like ANTLR provide multiple implementation languages to generate a parser for. 

\begin{GenericCode}[float,numbers=none,caption=Attributed Grammar for Coco-2 for simple arithmetic expressions., label=lst:Coco2ATG]
Expr<<out int e>> =      LOCAL<<int t = 0; e = 0;>>
  Term<<out e>>             
  { '+' Term<<out t>>    SEM<<e = e + t;>>
  | '-' Term<<out t>>    SEM<<e = e - t;>>
  }.

Term<<out int t>> =      LOCAL<<int f = 0; t = 0;>>
  Fact<<out t>>
  { '*' Fact<<out f>>    SEM<<t = t * f;>>
  | '/' Fact<<out f>>    SEM<<t = t / f;>>
  }.
  
Fact<<out int f>> =      LOCAL <<f = 0;>>
    number<<out f>>
  | '(' Expr<<out f>> ')'.

\end{GenericCode}

\section{ANTLR}

In this section, the parser generator ANTLR (ANother Tool for Language Recognition) is explained. First, a general overview of the history of ANTLR is given, followed by the introduction of the parsing algorithm currently employed by ANTLR, namely ALL(*). Finally, the general functionality of ANTLR is explained.  

\subsection{History}

"ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files". As the acronym of ANTLR states, it is a tool for language recognition. ANTLR was first released in 1992 and has since then been in continuous development. The original creator and maintainer of the project is Terence Parr. ANTLR is written in Java and is open sourced under the BSD license. Its source code can be viewed on GitHub\footnote{https://github.com/antlr/antlr4}. 

Many projects utilize ANTLR. Notable examples include the Java object-relational mapping tool \cite{HibernateWeb2024} and the NoSQL database Apache \textcite{Cassandra2024}.

ANTLR originally started as the master thesis of Terrence Parr \parencite{PCCTSHistory1994}. A first alpha release was created in 1990, that only generated LL(1) parsers. Version 1 of ANTLR incorporated a new parsing algorithm developed by Parr that allowed to create parsers for LL(k) grammars \parencite{parrPhd1993}. Version 2 then provided incremental improvements.   

Version 3, released in 2006 introduced another a new parsing algorithm called LL(*) \parencite{LLSParsing2011}. The LL(*) parsing strategy performs parsing decisions at parse-time with a dynamic lookahead. The number of lookahead tokens increases to an arbitrary amount and decreases again using backtracking. However, the maximum amount of $k$ lookahead tokens still needs to be specified. Version 3 also introduced ANTLRWorks\footnote{https://www.antlr3.org/works}, a graphical IDE for the construction of ANTLR grammars.

The current version 4, released in 2013 again introduced a new parsing algorithm Adaptive-LL(*) or ALL(*). The most significant improvement of ALL(*) over LL(*) is that the maximum number of lookahead tokens no longer needs to be specified. ANTLR v4 added support for the visitor and listener patterns\footnote{https://github.com/antlr/antlr4/blob/dev/doc/listeners.md}, enabling easier interaction with the syntax tree. 

\subsection{Parsing Algorithm Adaptive-LL(*)}
\label{sec:allstar}

The Adaptive-LL(*) or ALL(*) parsing strategy is introduced in the paper "Adaptive LL(*) parsing: the power of dynamic analysis" by \textcite{ALLParsing2014} and is the basis for this section. This parsing algorithm is used  for ANTLR version 4. As the title suggests, ALL(*) performs the analysis of the grammar at parse time. 

\subsubsection{Limitations of LL(*) Parsing Algorithm}

To understand the need for ALL(*), it is necessary to highlight why the previous strategy LL(*) is insufficient. LL(*), introduced by \textcite{parr2011ll}, was developed as an improvement to the existing general LL (GLL) \parencite{GLL2010} and general LR (GLR) \parencite{tomita1991generalized} parsers. For ambiguous grammars, these parsers return multiple parse trees, which is undesirable for parsers of programming languages. GLL and GLR are  designed for natural languages, which are inherently ambiguous. LL(*) overcomes these limitations by using regular expressions that are stored inside a deterministic finite automaton (DFA) to offer mostly deterministic parsing. Using the DFA allows for regular lookahead even though the grammar itself is context-free. 

However, the LL(*) grammar condition cannot be checked statically, leading to the case that sometimes no regular expression is found that distinguishes the possible productions. Such situations are detected by static analysis and then backtracking is used instead. Backtracking however comes with the disadvantage that for rules in the format $A \rightarrow a\;|\;a\;b$, the second alternative will never be matched, since backtracking always chooses the first alternative. 

\subsubsection{Dynamic Grammar Analysis with ALL(*)}

With ANTLR version 4 the parsing strategy Adaptive-LL(*) or ALL(*) was introduced. The main difference to ANTLR version 3 is that the grammar analysis is now performed at parse-time, and is no longer static. This overcomes the limitations of the static analysis LL(*) performs and enables the generation of correct parsers for context-free grammars. The only exception are grammars that contain indirect or hidden left-recursion\footnote{Indirect left-recursion is a rule like $A \rightarrow Bx, B \rightarrow Ay$. $\epsilon$ productions cause hidden left-recursion. Take a rule $B \rightarrow \epsilon$ that produces only the empty chain $\epsilon$ and another rule $A \rightarrow BA$. Since B's only production is to $\epsilon$ the second rule causes a left-recursion. }. From an engineering perspective it was seen to be too much effort to remedy this, since these grammars are deemed not to be common. Direct left-recursion is possible, because ANTLR rewrites the grammar to be non-direct left-recursive before passing it to the ALL(*) parsing algorithm. 

At a decision point (a rule containing multiple alternatives), ALL(*) starts a subparser for each alternative in pseudo-parallel. A subparser tries to match the remaining input to the selected alternative. If the input does not match, the subparser dies off. All subparsers process one symbol at the time in pseudo-parallel. This guarantees that the correct alternative can be found with minimum lookahead. In the case of ambiguity due to multiple subparsers reaching the end of file or coalescing, the first alternative will be chosen. 

The performance of ALL(*) is improved by employing a cache. This cache is implemented in the form of a DFA. The DFA stores the same information as the DFA generated by LL(*) from static analysis. After a lookahead, the DFA stores which production resulted from the lookahead phrase. If at a later time the same lookahead phrase is being processed, the correct production can be retrieved from the DFA. Theoretically, a DFA is not able to recognize a context-free grammar, however due to the analysis being performed at parse time, the analysis only needs to be performed on the remaining input. Since the remaining input is a subset of the context making it regular. Another optimization is the usage of a graph-structured stack (GSS). The GSS makes sure that during the prediction, no computation is performed twice, effectively acting as a cache. 

%In some cases it is necessary for ALL(*) to examine the parse stack to make a decision. 
%section about SLL
The theoretical runtime complexity of ALL(*) is $O(n^4)$. This stems from the fact that in the worst case the ALL(*) parser needs to make a prediction for each symbol and each launched subparser then needs to inspect the entire remaining input. In practice ALL(*) performs linearly for the syntax of common programming languages like Java or C\verb|#|.


\subsection{Functionality}

ANTLR generates a combined lexer and parser from a single grammar file. The generated parser is a recursive descent parser. ANTLR supports various implementation languages such as Java, C\verb|#| and C++. The syntax used by the ANTLR grammar supports extended BNF (EBNF) like operators such as \texttt{?}. To interact with the generated parser, ANTLR optionally generates interfaces and implementations for the listener and visitor pattern.

ALL(*) does not use a separate lexical analysis phase. Instead lexical and syntactical analysis are integrated into a unified process. Lexical rules are treated as parser rules, therefore a separate lexical analysis phase is not needed. Since the phases are combined, it is possible for ALL(*) to perform context-sensitive lexing. The lexer can make a decision based on the current parsing context. The parsing is directly performed on the raw input stream and not on a separate token stream. 

\subsubsection{Semantic Predicates}

ANTLR supports the definition of so-called \textit{semantic predicates}. Semantic predicates are boolean expressions, defined in the host language. If a semantic predicate is present for a production, the production can only be accepted if the semantic predicate evaluates to true. Semantic predicates are expressed inside \verb|{ }| parenthesis followed by $?$. Listing \ref{lst:ANTLRSemPred} shows an example use case of a semantic predicate. The rule \texttt{blockEnd} contains a semantic predicate specifying that the production can only be accepted if there is still a block on the stack. Otherwise the analysis fails, and an error is reported.

A semantic predicate also has access to the current token. This enables conditions that directly interact with the input. For example separate productions for even and uneven numbers could be used. The semantic predicate then checks if the number is even or not.  


\subsubsection{Semantic Actions}

In ANTLR grammars, semantic actions can be used. Semantic actions can be added to every parser rule, before, in between and after symbols. Similar to semantic predicates, the semantic actions are defined in the implementation language. Semantic actions are defined inside \verb|{ }| parenthesis. To access a symbol, the name of the symbol prefixed by \verb|$| can be used. In Listing \ref{lst:ANTLRSemPred} semantic actions are used in the \texttt{blockStart} \texttt{blockEnd} rules. For the \texttt{blockEnd} it has to be noted that the semantic predicate and action can be used together. 

% semantic actions

\begin{AntlrCode}[float,numbers=none,caption=Example grammar using a semantic predicate and a semantic action., label=lst:ANTLRSemPred]
grammar Example;
@members {
    java.util.Stack<String> blockStack = new java.util.Stack<>();
}

program: statement* EOF;

statement: 
      blockStart
    | blockEnd
    | otherStatement
    ;

blockStart: 'begin' { blockStack.push("block"); };

blockEnd: 'end' { !blockStack.isEmpty() }? { blockStack.pop(); };

otherStatement: 'print' IDENTIFIER;

IDENTIFIER: [a-zA-Z_][a-zA-Z_0-9]*;

WS  : [ \t\r\n]+ -> skip;
\end{AntlrCode}


\subsubsection{Alternative Labels for Rule Alternatives}

Per default, ANTLR generates one method for each rule. In the case of multiple alternatives for a rule, the handling of the alternatives would need to be done manually. Therefore, ANTLR offers the possibility to attach a label to each of the alternatives. Then, a method for each alternative will be generated separately. One use case is highlighted in listing \ref{lst:ANTLRRuleAlt}. The \texttt{type} rule matches either one of the four types. Each alternative has a label associated to it by using \verb|#| as the prefix for the alternative name. With this definition, four methods will be generated corresponding to each of the alternatives as explained above.     

\begin{AntlrCode}[float,numbers=none,caption=Example rule using alternative labels for the rule alternatives., label=lst:ANTLRRuleAlt]
  type:
        'int'     #IntType
      | 'bool'    #BoolType
      | 'long'    #LongType
      | 'string'  #StringType
      ;
\end{AntlrCode}

\section{Syntax Tree and Abstract Syntax Tree (AST)}

A syntax tree is a hierarchical representation of the syntactical structure of a sentence. Also referred to as a parse tree, this representation is usually generated by a parser. A syntax tree contains the information of the entire sentence based on the grammar of that language. Each inner node in the syntax tree corresponds to a rule in the grammar. The leaf nodes represent terminal symbols and inner nodes are non-terminal symbols. Concatenating the leaf nodes from left to right of the syntax tree results in the original sentence from which the syntax tree was constructed from. 

Listing \ref{lst:SyntaxTreeEx} shows the syntax tree of the arithmetic expression \texttt{5 * 3 + 7} based on the grammar in \ref{lst:Coco2ATG}. 
%TODO
This syntax tree contains the non-terminal symbol \texttt{Expression, Term, Fact} and the terminal class \texttt{number}. The expression is built from two terms and one operator. The left term represents a multiplication consisting of two factors and an operator. All factors in the syntax tree contain the terminal class \texttt{number} which hold the concrete numbers. This structure further represents the precedence rules of arithmetic operations directly in the syntax tree.  

%\subsection{Abstract Syntax Tree (AST)}
In an abstract syntax tree (AST) only a subset of the nodes from the original syntax tree are included. The goal is to focus on the semantic aspects of the syntax tree. Syntactical details, e.g., semicolons are omitted. 

The generation of an AST from a syntax tree can be done in multiple ways. One method is to generate the AST during the parse, which increases performance since the syntax tree does not need to be constructed and traversed. This can be implemented by using an attributed grammar with semantic actions that embed the AST generation code directly into the parser. Parsers like ANTLR also support the listener pattern to execute code during the parse. Alternatively, the AST can be generated after the parse phase from the syntax tree. To traverse the syntax tree, the visitor pattern can be used for example.  

The AST is then used in the subsequent stages of a compiler. This transformation is performed to create a new tree which omits all information that is of no importance to the following stages of the compiler. Subsequent code optimization may further slim down the AST. 

Continuing with the previous example, listing \ref{lst:ASTEx} shows the AST of the arithmetic expression \texttt{5 * 3 + 7}. This AST still contains the same semantic meaning as the full syntax tree, however it needs fewer nodes for that. Instead of using the non-terminal symbols, the operator is used, effectively encoding the same information. In this example, the node count can be reduced from 14 to 5.

\begin{GenericCode}[float,numbers=none,caption=Syntax tree of the arithmetic expression \texttt{5 * 3 + 7} based on the grammar in listing \ref{lst:Coco2ATG}., label=lst:SyntaxTreeEx]
                                       Expr   
                                   /    |    \
                                Term    +    Term
                              /   |   \        |    
                           Fact   *   Fact    Fact  
                            |          |       |
                          number     number  number
                            |          |       |
                            5          3       7
\end{GenericCode}

\begin{GenericCode}[float,numbers=none,caption=Abstract syntax tree of the arithmetic expression \texttt{5 * 3 + 7}., label=lst:ASTEx]
                                      +
                                    /   \
                                   *     7
                                 /   \
                                3     5
\end{GenericCode}

\section{Visitor-Pattern for Tree Transformation}

In the case that a syntax tree has already been built, the visitor-pattern can be used to create an AST from the syntax tree. Using the visitor-pattern, the syntax tree gets traversed and then step by step the AST is constructed. The visitor-pattern allows for the separation of algorithms from the objects they operate on. Instead of including the code for the generation of an AST object in the syntax tree object, a separate object, a so-called \textit{visitor} takes care of this. 

To implement the visitor-pattern for a syntax tree, the best approach is to use interfaces or abstract classes for the nodes of the syntax tree and the visitors. Listing \ref{lst:ListPatIntEx} shows a possible implementation for an interface and abstract class in Kotlin. This code is based on the syntax tree shown in listing \ref{lst:SyntaxTreeEx}. Each class for the syntax tree implements the  abstract class \texttt{SyntaxTreeNode}. For the visitor class, the \texttt{SyntaxTreeVisitor} interface needs to be implemented. \texttt{SyntaxTreeNode} and \texttt{SyntaxTreeVisitor} are both generic classes. This allows the implementation of the visitor to use an arbitrary type as a return value. Multiple visitors can then be implemented using the generics, so that each visitor can return one type for the AST. In this case it is helpful to create an abstract base visitor that provides an empty implementation for all interface's methods. Then the concrete visitor only needs to override the methods that are relevant for the specific AST type.  

A \texttt{SyntaxTreeNode} can then be visited by calling its \texttt{accept} method. Inside the \texttt{accept} method, the appropriate method of the \texttt{SyntaxTreeVisitor} will be called. As can be seen in listing \ref{lst:ListPatNumbNode} the \texttt{NumberNode} calls the \texttt{visitNumberNode} with itself as the parameter. This behavior is analogous for all other nodes of the syntax tree. 


\begin{KotlinCode}[float,numbers=none,caption=Interface and abstract class used to implement the visitor-pattern., label=lst:ListPatIntEx]
interface SyntaxTreeVisitor<T> {
    fun visitNumberNode(node: NumberNode): T
    fun visitOperatorNode(node: OperatorNode): T
}

sealed class SyntaxTreeNode {
    abstract fun <T> accept(visitor: SyntaxTreeVisitor<T>): T
}
\end{KotlinCode}


\begin{KotlinCode}[float,numbers=none,caption=Implementation of the \texttt{NumberNode} class inheriting from the \texttt{SyntaxTreeNode}., label=lst:ListPatNumbNode]
data class NumberNode(val value: Int) : SyntaxTreeNode() {
    override fun <T> accept(visitor: SyntaxTreeVisitor<T>): <T> {
        return visitor.visitNumberNode(this)
    }
}
\end{KotlinCode}


\section{Listener-Pattern for Tree Transformation}

The listener-pattern is used for \textit{listening} to events or notifications from another object. In the context of parsing, the listener-pattern is used to handle parse events coming from the parser. This includes events such as beginning and finishing the parse of a node of the syntax tree. When using the listener-pattern the parse tree is only traversed once. This is because the events get pushed to the listeners during the parse. 

To implement the listener-pattern for the construction of an AST, a listener interface is needed. The listener interface contains method declarations for beginning and finishing the parse of each node type. The methods take the syntax tree node as the input parameter. A possible implementation for the listener interface is shown in \ref{lst:ListPatExprList}. In case of the \textit{enter} methods, the symbols for the syntax tree node have not been parsed yet, so no data from them is available yet.

A concrete listener will then implement the interface and register/subscribe itself for the events of the parser. When the parser begins or finishes a parsing a node, it will call the respective method with the parsed syntax tree node for all listeners. 

\begin{KotlinCode}[float,numbers=none,caption=Implementation of the \texttt{ExpressionListener} interface., label=lst:ListPatExprList]
interface ExpressionListener {
    fun enterExpr(node: Expression)
    fun exitExpr(node: Expression)

    fun enterTerm(term: Term)
    fun exitTerm(term: Term)

    fun enterFact(fact: Fact)
    fun exitFact(fact: Fact)

    fun enterNumber(number: Number)
    fun exitNumber(number: Number)
}
  \end{KotlinCode}

\section{Summary}

This chapter discussed different strategies for the generation of an AST using the combined lexer and parser generator ANTLR. Namely, the generation via the visitor-pattern, via the listener-pattern and via an ATG. In the following chapter the Java Virtual Machine (JVM) is explained and an overview of the bytecode generation library ObjectWeb ASM is given. 